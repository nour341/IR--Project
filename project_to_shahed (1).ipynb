{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YtPqs0szUjG",
        "outputId": "fa1f6a1f-f91a-4154-ec2a-5f6b78fd9d3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ir_datasets\n",
            "  Downloading ir_datasets-0.5.7-py3-none-any.whl (337 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m337.9/337.9 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from ir_datasets) (4.12.3)\n",
            "Collecting inscriptis>=2.2.0 (from ir_datasets)\n",
            "  Downloading inscriptis-2.5.0-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.4/45.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.5.2 in /usr/local/lib/python3.10/dist-packages (from ir_datasets) (4.9.4)\n",
            "Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.10/dist-packages (from ir_datasets) (1.25.2)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ir_datasets) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from ir_datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from ir_datasets) (4.66.4)\n",
            "Collecting trec-car-tools>=2.5.4 (from ir_datasets)\n",
            "  Downloading trec_car_tools-2.6-py3-none-any.whl (8.4 kB)\n",
            "Collecting lz4>=3.1.10 (from ir_datasets)\n",
            "  Downloading lz4-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting warc3-wet>=0.2.3 (from ir_datasets)\n",
            "  Downloading warc3_wet-0.2.3-py3-none-any.whl (13 kB)\n",
            "Collecting warc3-wet-clueweb09>=0.2.5 (from ir_datasets)\n",
            "  Downloading warc3-wet-clueweb09-0.2.5.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting zlib-state>=0.1.3 (from ir_datasets)\n",
            "  Downloading zlib-state-0.1.6.tar.gz (9.5 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ijson>=3.1.3 (from ir_datasets)\n",
            "  Downloading ijson-3.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (111 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.8/111.8 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting unlzw3>=0.2.1 (from ir_datasets)\n",
            "  Downloading unlzw3-0.2.2-py3-none-any.whl (6.1 kB)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.4.1->ir_datasets) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->ir_datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->ir_datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->ir_datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->ir_datasets) (2024.2.2)\n",
            "Collecting cbor>=1.0.0 (from trec-car-tools>=2.5.4->ir_datasets)\n",
            "  Downloading cbor-1.0.0.tar.gz (20 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: warc3-wet-clueweb09, zlib-state, cbor\n",
            "  Building wheel for warc3-wet-clueweb09 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for warc3-wet-clueweb09: filename=warc3_wet_clueweb09-0.2.5-py3-none-any.whl size=18919 sha256=2d7b9027b42d16931617943eb6ad843041a1816e6364255f73ebdccea2fe747b\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/d7/91/7ffb991df87e62355d945745035470ba2616aa3d83a250b5f9\n",
            "  Building wheel for zlib-state (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for zlib-state: filename=zlib_state-0.1.6-cp310-cp310-linux_x86_64.whl size=21163 sha256=1cee0a128f0b0394611555e932e35e0a80abd6a411859f7ae3f4cc7e0f4a4ff2\n",
            "  Stored in directory: /root/.cache/pip/wheels/32/72/7e/aff80f26e926b6e1fb08dfb52aba03c0e058f5e2258deb50a9\n",
            "  Building wheel for cbor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cbor: filename=cbor-1.0.0-cp310-cp310-linux_x86_64.whl size=53431 sha256=53d97f698892abbe627e8f0cc5d7a48dfba20aff027e1263cbfbf4ba73fe9fca\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/df/c9/b39e40eccaf76dbd218556639a6dc81562226f4c6a64902c85\n",
            "Successfully built warc3-wet-clueweb09 zlib-state cbor\n",
            "Installing collected packages: warc3-wet-clueweb09, warc3-wet, ijson, cbor, zlib-state, unlzw3, trec-car-tools, lz4, inscriptis, ir_datasets\n",
            "Successfully installed cbor-1.0.0 ijson-3.2.3 inscriptis-2.5.0 ir_datasets-0.5.7 lz4-4.3.3 trec-car-tools-2.6 unlzw3-0.2.2 warc3-wet-0.2.3 warc3-wet-clueweb09-0.2.5 zlib-state-0.1.6\n"
          ]
        }
      ],
      "source": [
        "pip install ir_datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "R9w0FIlgoSp9"
      },
      "outputs": [],
      "source": [
        "import ir_datasets\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.cluster import KMeans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vmas_cBHotp8",
        "outputId": "7574f3b3-1b0e-44f5-a0cf-66ad4b7b146b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QdzkvWx-zk07"
      },
      "outputs": [],
      "source": [
        "# load data\n",
        "dataset1 = ir_datasets.load('antique/test/non-offensive')\n",
        "dataset2 = ir_datasets.load('beir/quora/test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3MFrjCzNz7aQ"
      },
      "outputs": [],
      "source": [
        "ps = PorterStemmer()\n",
        "stop_words = set(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "c8PlhoVGz7c7"
      },
      "outputs": [],
      "source": [
        "# preprocess data\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    words = word_tokenize(text)\n",
        "    processed_words = [ps.stem(word) for word in words if word not in stop_words]\n",
        "    return ' '.join(processed_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "bdhT1o4Tz7e4"
      },
      "outputs": [],
      "source": [
        "# process_documents\n",
        "def process_documents(dataset):\n",
        "    documents = []\n",
        "    for doc in dataset.docs_iter():\n",
        "        processed_text = preprocess_text(doc.text)\n",
        "        documents.append({\n",
        "            'doc_id': doc.doc_id,\n",
        "            'text': processed_text\n",
        "        })\n",
        "    return documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0M-1wO_z7hO",
        "outputId": "52b36a75-4465-4442-da85-bc09dfbcc082"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[INFO] Please confirm you agree to the authors' data usage agreement found at <https://ciir.cs.umass.edu/downloads/Antique/readme.txt>\n",
            "[INFO] If you have a local copy of https://ciir.cs.umass.edu/downloads/Antique/antique-collection.txt, you can symlink it here to avoid downloading it again: /root/.ir_datasets/downloads/684f7015aff377062a758e478476aac8\n",
            "[INFO] [starting] https://ciir.cs.umass.edu/downloads/Antique/antique-collection.txt\n",
            "[INFO] [finished] https://ciir.cs.umass.edu/downloads/Antique/antique-collection.txt: [00:01] [93.6MB] [67.2MB/s]\n",
            "[INFO] [starting] building docstore\n",
            "[INFO] [starting] opening zip file\n",
            "[INFO] If you have a local copy of https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/quora.zip, you can symlink it here to avoid downloading it again: /root/.ir_datasets/downloads/18fb154900ba42a600f84b839c173167\n",
            "[INFO] [starting] https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/quora.zip\n",
            "docs_iter:   0%|                                    | 0/522931 [00:00<?, ?doc/s]\n",
            "https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/quora.zip: 0.0%| 0.00/15.9M [00:00<?, ?B/s]\u001b[A\n",
            "https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/quora.zip: 0.4%| 65.5k/15.9M [00:00<00:50, 313kB/s]\u001b[A\n",
            "https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/quora.zip: 0.8%| 131k/15.9M [00:00<00:38, 409kB/s] \u001b[A\n",
            "https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/quora.zip: 1.2%| 197k/15.9M [00:00<00:34, 455kB/s]\u001b[A\n",
            "https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/quora.zip: 1.9%| 295k/15.9M [00:00<00:28, 544kB/s]\u001b[A\n",
            "https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/quora.zip: 3.5%| 557k/15.9M [00:00<00:17, 853kB/s]\u001b[A\n",
            "https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/quora.zip: 6.7%| 1.06M/15.9M [00:00<00:10, 1.39MB/s]\u001b[A\n",
            "https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/quora.zip: 13.3%| 2.11M/15.9M [00:00<00:05, 2.42MB/s]\u001b[A\n",
            "https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/quora.zip: 26.4%| 4.18M/15.9M [00:00<00:02, 4.24MB/s]\u001b[A\n",
            "https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/quora.zip: 39.4%| 6.24M/15.9M [00:01<00:01, 5.62MB/s]\u001b[A\n",
            "https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/quora.zip: 52.4%| 8.31M/15.9M [00:01<00:01, 6.81MB/s]\u001b[A\n",
            "https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/quora.zip: 65.4%| 10.4M/15.9M [00:01<00:00, 7.83MB/s]\u001b[A\n",
            "\n",
            "\u001b[A[INFO] [finished] https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/quora.zip: [00:01] [15.9MB] [10.9MB/s]\n",
            "docs_iter:   0%|                                    | 0/522931 [00:02<?, ?doc/s]\n",
            "https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/quora.zip: [00:01] [15.9MB] [10.8MB/s]\u001b[A\n",
            "[INFO] [finished] opening zip file [2.28s]\n",
            "docs_iter: 100%|████████████████████| 522931/522931 [00:11<00:00, 43926.47doc/s]\n",
            "[INFO] [finished] docs_iter: [00:11] [522931doc] [43921.35doc/s]\n",
            "[INFO] [finished] building docstore [11.92s]\n"
          ]
        }
      ],
      "source": [
        "documents1 = process_documents(dataset1)\n",
        "documents2 = process_documents(dataset2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "4BCJ2HRNz7l2"
      },
      "outputs": [],
      "source": [
        "# TF-IDF\n",
        "def create_tfidf_vectors(documents):\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    doc_texts = [doc['text'] for doc in documents]\n",
        "    vectors = vectorizer.fit_transform(doc_texts)\n",
        "    return vectorizer, vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "npO6o_Wwz7oZ"
      },
      "outputs": [],
      "source": [
        "vectorizer1, doc_vectors1 = create_tfidf_vectors(documents1)\n",
        "vectorizer2, doc_vectors2 = create_tfidf_vectors(documents2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hz5kM6bYz7qu",
        "outputId": "536f9455-4b2f-4c87-f048-42a5e2bfeb2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset 1: 403666 documents, 237358 features\n",
            "Dataset 2: 522931 documents, 85297 features\n"
          ]
        }
      ],
      "source": [
        "print(f\"Dataset 1: {doc_vectors1.shape[0]} documents, {doc_vectors1.shape[1]} features\")\n",
        "print(f\"Dataset 2: {doc_vectors2.shape[0]} documents, {doc_vectors2.shape[1]} features\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "1-u_hskQz7t2"
      },
      "outputs": [],
      "source": [
        "#process_query\n",
        "def process_query(query, vectorizer):\n",
        "    processed_query = preprocess_text(query)\n",
        "    return vectorizer.transform([processed_query])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zxw_BoaJz7wL"
      },
      "outputs": [],
      "source": [
        "# match_and_rank\n",
        "#def match_and_rank(query, vectorizer, doc_vectors):\n",
        "#    query_vector = process_query(query, vectorizer)\n",
        "#    scores = cosine_similarity(query_vector, doc_vectors).flatten()\n",
        "#    ranked_doc_indices = scores.argsort()[::-1]\n",
        "#    return ranked_doc_indices, scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "EwMRYCMVng7t"
      },
      "outputs": [],
      "source": [
        "def match_and_rank(query, vectorizer, doc_vectors, documents):\n",
        "    query_vector = process_query(query, vectorizer)\n",
        "    scores = cosine_similarity(query_vector, doc_vectors).flatten()\n",
        "    ranked_doc_indices = scores.argsort()[::-1]\n",
        "    ranked_documents = [(documents[idx]['doc_id'], scores[idx]) for idx in ranked_doc_indices]\n",
        "    return ranked_documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "GrB_e4Ymz7yu"
      },
      "outputs": [],
      "source": [
        "# test query\n",
        "search_query = \"how to improve search engine performance\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9cDtOJEbz70n"
      },
      "outputs": [],
      "source": [
        "# similarty TF-IDF\n",
        "#ranked_indices1, scores1 = match_and_rank(search_query, vectorizer1, doc_vectors1)\n",
        "#ranked_indices2, scores2 = match_and_rank(search_query, vectorizer2, doc_vectors2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "t4y6q9XYnxuD"
      },
      "outputs": [],
      "source": [
        "# similarity TF-IDF\n",
        "ranked_docs1 = match_and_rank(search_query, vectorizer1, doc_vectors1, documents1)\n",
        "ranked_docs2 = match_and_rank(search_query, vectorizer2, doc_vectors2, documents2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5LQLX_Yz73Z",
        "outputId": "038dbc9f-27d3-4864-9617-1522adfd5c63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TF-IDF Ranking Results for Dataset 1:\n",
            "Document ID: 2538279_4, Score: 0.6402472367428559\n",
            "Document ID: 3774613_1, Score: 0.5390514687446829\n",
            "Document ID: 296379_5, Score: 0.509534647726315\n",
            "Document ID: 2075461_1, Score: 0.48487446772435294\n",
            "Document ID: 140691_1, Score: 0.48487446772435294\n",
            "Document ID: 1018545_3, Score: 0.4842181881021651\n",
            "Document ID: 4295697_1, Score: 0.4592582673175454\n",
            "Document ID: 547868_3, Score: 0.45561109289893525\n",
            "Document ID: 2877208_3, Score: 0.4314629214060672\n",
            "Document ID: 4431784_1, Score: 0.42441823698800113\n"
          ]
        }
      ],
      "source": [
        "#print(\"TF-IDF Ranking Results for Dataset 1:\")\n",
        "#for idx in ranked_indices1[:10]:\n",
        "#    print(f\"Document ID: {documents1[idx]['doc_id']}, Score: {scores1[idx]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTafzY2moCYO",
        "outputId": "ec88cb69-0219-4d73-de5a-60eeed7c06aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF Ranking Results for Dataset 1:\n",
            "Document ID: 4237774_1, Score: 0.6710499975277999\n",
            "Document ID: 3493286_2, Score: 0.5881821964165571\n",
            "Document ID: 1698674_2, Score: 0.5732694835610638\n",
            "Document ID: 4115722_0, Score: 0.5246257305238725\n",
            "Document ID: 607425_0, Score: 0.5239244655227959\n",
            "Document ID: 4431784_1, Score: 0.5035777198769322\n",
            "Document ID: 2076701_3, Score: 0.5030860281142819\n",
            "Document ID: 2344295_4, Score: 0.4955479165590613\n",
            "Document ID: 1759207_3, Score: 0.47951935092804154\n",
            "Document ID: 2075461_1, Score: 0.4746355297580474\n"
          ]
        }
      ],
      "source": [
        "print(\"TF-IDF Ranking Results for Dataset 1:\")\n",
        "for doc_id, score in ranked_docs1[:10]:\n",
        "    print(f\"Document ID: {doc_id}, Score: {score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTRVW_VxoFtM",
        "outputId": "430f9391-27b3-4f31-e374-051346282866"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF Ranking Results for Dataset 2:\n",
            "Document ID: 67268, Score: 0.7385739697136127\n",
            "Document ID: 482830, Score: 0.6884830150245347\n",
            "Document ID: 89570, Score: 0.6884830150245347\n",
            "Document ID: 89571, Score: 0.6884830150245347\n",
            "Document ID: 169139, Score: 0.6741724492008523\n",
            "Document ID: 67269, Score: 0.6305590549141409\n",
            "Document ID: 404651, Score: 0.6305590549141409\n",
            "Document ID: 482831, Score: 0.6268292244597347\n",
            "Document ID: 404833, Score: 0.6242788042971892\n",
            "Document ID: 156260, Score: 0.6242788042971892\n"
          ]
        }
      ],
      "source": [
        "print(\"TF-IDF Ranking Results for Dataset 2:\")\n",
        "for doc_id, score in ranked_docs2[:10]:\n",
        "    print(f\"Document ID: {doc_id}, Score: {score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xz9ZCfyQ2V9Y",
        "outputId": "6d05cb80-09b2-4779-a21e-d36beb2a0ba0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TF-IDF Ranking Results for Dataset 2:\n",
            "Document ID: 233080, Score: 0.6938439099533338\n",
            "Document ID: 210216, Score: 0.6923011121673248\n",
            "Document ID: 233081, Score: 0.6773129463878851\n",
            "Document ID: 256946, Score: 0.6670372859153133\n",
            "Document ID: 108503, Score: 0.6134935471549455\n",
            "Document ID: 108504, Score: 0.6134935471549455\n",
            "Document ID: 59515, Score: 0.6083386508660562\n",
            "Document ID: 59516, Score: 0.6010703833537651\n",
            "Document ID: 263692, Score: 0.5509190665897268\n",
            "Document ID: 417903, Score: 0.5440910539548532\n"
          ]
        }
      ],
      "source": [
        "#print(\"TF-IDF Ranking Results for Dataset 2:\")\n",
        "#for idx in ranked_indices2[:10]:\n",
        "#    print(f\"Document ID: {documents2[idx]['doc_id']}, Score: {scores2[idx]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "PFDQTsxO2WCY"
      },
      "outputs": [],
      "source": [
        "# Documents Clustering using K-Means\n",
        "def cluster_documents(doc_vectors, num_clusters=5):\n",
        "    kmeans = KMeans(n_clusters=num_clusters, n_init=10).fit(doc_vectors)\n",
        "    return kmeans.labels_, kmeans.cluster_centers_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Bd70QkkZ2WOm"
      },
      "outputs": [],
      "source": [
        "num_clusters = 5\n",
        "labels1, centers1 = cluster_documents(doc_vectors1, num_clusters)\n",
        "labels2, centers2 = cluster_documents(doc_vectors2, num_clusters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Bio33GG2tG9F"
      },
      "outputs": [],
      "source": [
        "# Display Clustering Results\n",
        "#def display_clusters(labels, documents, num_clusters):\n",
        "#    clusters = {i: [] for i in range(num_clusters)}\n",
        "#    for label, doc in zip(labels, documents):\n",
        "#        clusters[label].append(doc['doc_id'])\n",
        "#    return clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "k28SQQVLteRU"
      },
      "outputs": [],
      "source": [
        "#clusters1 = display_clusters(labels1, documents1, num_clusters)\n",
        "#clusters2 = display_clusters(labels2, documents2, num_clusters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQTLOQ5Ftg5D",
        "outputId": "b7592b23-76b4-47f7-aab4-aebcb845e309"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# print(\"\\nClustering Results for Dataset 1:\")\n",
        "# for cluster_id, doc_ids in clusters1.items():\n",
        "#     print(f\"Cluster {cluster_id}: {doc_ids}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvc9h3uxthBj",
        "outputId": "fe084322-ffea-43bf-82ca-98912acaa388"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# print(\"\\nClustering Results for Dataset 2:\")\n",
        "# for cluster_id, doc_ids in clusters2.items():\n",
        "#     print(f\"Cluster {cluster_id}: {doc_ids}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "DK-SUGlVtm-x"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def group_documents_by_cluster(labels):\n",
        "    clusters = defaultdict(list)\n",
        "    for doc_id, cluster_id in enumerate(labels):\n",
        "        clusters[cluster_id].append(doc_id)\n",
        "    return clusters"
      ],
      "metadata": {
        "id": "XqqACJKTYq20"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clusters1 = group_documents_by_cluster(labels1)\n",
        "clusters2 = group_documents_by_cluster(labels2)"
      ],
      "metadata": {
        "id": "MWxVPOx9Ysxr"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_cluster_summary(clusters, dataset_name):\n",
        "    print(f\"\\nClustering Results for {dataset_name}:\")\n",
        "    for cluster_id, doc_ids in clusters.items():\n",
        "        print(f\"Cluster {cluster_id}: {len(doc_ids)} documents\")\n",
        "        print(f\"Sample document IDs: {doc_ids[:10]}\")"
      ],
      "metadata": {
        "id": "wWBUoEZ-Yuq-"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_cluster_summary(clusters1, \"Dataset 1\")\n",
        "print_cluster_summary(clusters2, \"Dataset 2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jnGffiqYx35",
        "outputId": "6785b6ae-9ba0-4bde-c83a-45c381388d32"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Clustering Results for Dataset 1:\n",
            "Cluster 0: 264182 documents\n",
            "Sample document IDs: [0, 1, 4, 5, 6, 8, 9, 10, 11, 12]\n",
            "Cluster 3: 76396 documents\n",
            "Sample document IDs: [2, 3, 7, 15, 17, 32, 47, 56, 60, 72]\n",
            "Cluster 2: 35794 documents\n",
            "Sample document IDs: [13, 20, 25, 43, 61, 70, 71, 83, 88, 91]\n",
            "Cluster 4: 17429 documents\n",
            "Sample document IDs: [69, 119, 128, 149, 153, 198, 232, 270, 280, 357]\n",
            "Cluster 1: 9865 documents\n",
            "Sample document IDs: [201, 267, 281, 293, 299, 303, 394, 395, 397, 541]\n",
            "\n",
            "Clustering Results for Dataset 2:\n",
            "Cluster 2: 446539 documents\n",
            "Sample document IDs: [0, 1, 2, 3, 5, 6, 7, 8, 9, 10]\n",
            "Cluster 0: 18276 documents\n",
            "Sample document IDs: [4, 16, 17, 20, 78, 321, 322, 407, 436, 442]\n",
            "Cluster 1: 13784 documents\n",
            "Sample document IDs: [37, 70, 138, 166, 234, 235, 269, 334, 351, 352]\n",
            "Cluster 4: 37159 documents\n",
            "Sample document IDs: [38, 39, 55, 56, 67, 68, 114, 117, 131, 175]\n",
            "Cluster 3: 7173 documents\n",
            "Sample document IDs: [69, 224, 225, 320, 461, 574, 640, 712, 1142, 1145]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eO1DuPY5Y9n0"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}