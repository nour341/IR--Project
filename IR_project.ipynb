{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cRQZSN48W0X",
        "outputId": "a1f8342e-6ffc-4d72-c671-60933c21d08b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ir_datasets in /usr/local/lib/python3.10/dist-packages (0.5.7)\n",
            "Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from ir_datasets) (4.12.3)\n",
            "Requirement already satisfied: inscriptis>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from ir_datasets) (2.5.0)\n",
            "Requirement already satisfied: lxml>=4.5.2 in /usr/local/lib/python3.10/dist-packages (from ir_datasets) (4.9.4)\n",
            "Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.10/dist-packages (from ir_datasets) (1.25.2)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ir_datasets) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from ir_datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from ir_datasets) (4.66.4)\n",
            "Requirement already satisfied: trec-car-tools>=2.5.4 in /usr/local/lib/python3.10/dist-packages (from ir_datasets) (2.6)\n",
            "Requirement already satisfied: lz4>=3.1.10 in /usr/local/lib/python3.10/dist-packages (from ir_datasets) (4.3.3)\n",
            "Requirement already satisfied: warc3-wet>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from ir_datasets) (0.2.3)\n",
            "Requirement already satisfied: warc3-wet-clueweb09>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ir_datasets) (0.2.5)\n",
            "Requirement already satisfied: zlib-state>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from ir_datasets) (0.1.6)\n",
            "Requirement already satisfied: ijson>=3.1.3 in /usr/local/lib/python3.10/dist-packages (from ir_datasets) (3.2.3)\n",
            "Requirement already satisfied: unlzw3>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from ir_datasets) (0.2.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.4.1->ir_datasets) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->ir_datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->ir_datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->ir_datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->ir_datasets) (2024.2.2)\n",
            "Requirement already satisfied: cbor>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from trec-car-tools>=2.5.4->ir_datasets) (1.0.0)\n"
          ]
        }
      ],
      "source": [
        "pip install ir_datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ir_datasets\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "from collections import defaultdict\n",
        "import re\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import csv\n",
        "import pickle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAuyaAIw8av5",
        "outputId": "4e678c98-557d-4e76-e984-bcc86ff1624e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# load data\n"
      ],
      "metadata": {
        "id": "Nq6WS2_b88BO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loadData(dataset):\n",
        "    documents = [{'doc_id': doc.doc_id, 'text': doc.text} for doc in dataset.docs_iter() if doc.text.strip() ]\n",
        "    qrels = defaultdict(list, {qrel.query_id: [(qrel.doc_id, qrel.relevance)] for qrel in dataset.qrels_iter()})\n",
        "    queries = {query.query_id: query.text for query in dataset.queries_iter() if query.text.strip() }\n",
        "    return qrels,queries,documents\n"
      ],
      "metadata": {
        "id": "C5zzM92BAz0S"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load data\n",
        "dataset1 = ir_datasets.load('antique/test/non-offensive')\n",
        "dataset2 = ir_datasets.load('beir/quora/test')"
      ],
      "metadata": {
        "id": "QnkTAoxw8xZl"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qrels1,queries1,documents1 =loadData(dataset1)\n",
        "qrels2,queries2,documents2 =loadData(dataset2)\n"
      ],
      "metadata": {
        "id": "o3yszkNCAsgq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ps = PorterStemmer()\n",
        "stop_words = set(stopwords.words('english'))"
      ],
      "metadata": {
        "id": "cbAC1Gb-8kih"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# preprocess data\n"
      ],
      "metadata": {
        "id": "TOpuA4PS8915"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_numbers_and_dates(text):\n",
        "        if not text:\n",
        "           return ''\n",
        "        if not isinstance(text, str):\n",
        "           return ''\n",
        "        number_pattern = r'\\d+'\n",
        "        date_pattern = r'\\d{1,2}/\\d{1,2}/\\d{4}'\n",
        "        symbol_pattern = r'[^\\w\\s]'\n",
        "        text = re.sub(number_pattern, '', text)\n",
        "        text = re.sub(date_pattern, '', text)\n",
        "        text = re.sub(symbol_pattern, '', text)\n",
        "\n",
        "        return text"
      ],
      "metadata": {
        "id": "FR2lzoLvJV2E"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove special characters and digits\n",
        "    text = re.sub(r\"[^a-zA-Z]\", \" \", text)\n",
        "    # remove numbers and dates\n",
        "    text = remove_numbers_and_dates(text)\n",
        "\n",
        "\n",
        "    # Tokenize the text into individual words\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words(\"english\"))\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "\n",
        "    # Lemmatize words\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "\n",
        "    # Join the tokens back into a single string\n",
        "    processed_text = \" \".join(tokens)\n",
        "\n",
        "    return processed_text"
      ],
      "metadata": {
        "id": "z1w8BTeD8pRD"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "def preprocessData(documents, queries, folder_name):\n",
        "    processed_docs_file = os.path.join(folder_name, 'processed_documents.csv')\n",
        "    processed_queries_file = os.path.join(folder_name, 'processed_queries.csv')\n",
        "\n",
        "    # Check if the processed files already exist\n",
        "    if os.path.exists(processed_docs_file) and os.path.exists(processed_queries_file):\n",
        "        # Load the processed data from the CSV files\n",
        "        processed_docs = pd.read_csv(processed_docs_file, header=None).values.tolist()\n",
        "        processed_queries = pd.read_csv(processed_queries_file, header=None).values.tolist()\n",
        "    else:\n",
        "        # Create the folder if it doesn't exist\n",
        "        if not os.path.exists(folder_name):\n",
        "            os.makedirs(folder_name)\n",
        "\n",
        "        # Process the documents and queries\n",
        "        processed_docs = [preprocess_text(doc['text']) for doc in documents]\n",
        "        processed_queries = [preprocess_text(query) for query in queries.values()]\n",
        "\n",
        "        # Save the processed data to CSV files\n",
        "        doc_df = pd.DataFrame(processed_docs)\n",
        "        doc_df.to_csv(processed_docs_file, index=False, header=False)\n",
        "\n",
        "        query_df = pd.DataFrame(processed_queries)\n",
        "        query_df.to_csv(processed_queries_file, index=False, header=False)\n",
        "\n",
        "    return processed_docs, processed_queries"
      ],
      "metadata": {
        "id": "jySfprFDBPZd"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_docs1,processed_queries1 = preprocessData(documents1,queries1,'folder_data1')\n",
        "processed_docs2,processed_queries2 = preprocessData(documents2,queries2,'folder_data2')\n"
      ],
      "metadata": {
        "id": "HiVYsVaPBHDo"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# vectorizer Data"
      ],
      "metadata": {
        "id": "G6aYNNfmBtny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from scipy.sparse import save_npz, load_npz\n",
        "import pickle\n",
        "\n",
        "def vectorizerData(processed_docs, processed_queries, folder_name):\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    # Define file paths\n",
        "    doc_vectors_file = os.path.join(folder_name, 'doc_vectors.npz')\n",
        "    query_vectors_file = os.path.join(folder_name, 'query_vectors.npz')\n",
        "    vectorizer_file = os.path.join(folder_name, 'vectorizer.pkl')\n",
        "\n",
        "    # Check if the files already exist\n",
        "    if os.path.exists(doc_vectors_file) and os.path.exists(query_vectors_file) and os.path.exists(vectorizer_file):\n",
        "        # Load existing vectors and vectorizer\n",
        "        doc_vectors = load_npz(doc_vectors_file)\n",
        "        query_vectors = load_npz(query_vectors_file)\n",
        "        with open(vectorizer_file, 'rb') as f:\n",
        "            vectorizer = pickle.load(f)\n",
        "    else:\n",
        "        # Transform documents and queries\n",
        "        doc_vectors = vectorizer.fit_transform(processed_docs)\n",
        "        query_vectors = vectorizer.transform(processed_queries)\n",
        "\n",
        "        # Save vectors and vectorizer\n",
        "        save_npz(doc_vectors_file, doc_vectors)\n",
        "        save_npz(query_vectors_file, query_vectors)\n",
        "        with open(vectorizer_file, 'wb') as f:\n",
        "            pickle.dump(vectorizer, f)\n",
        "\n",
        "    return doc_vectors, query_vectors, vectorizer\n"
      ],
      "metadata": {
        "id": "LjfaW4H6Jpo1"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TFIDF vectorizer"
      ],
      "metadata": {
        "id": "guVzHrG4B21H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc_vectors1,query_vectors1,vectorizer1 = vectorizerData(processed_docs1,processed_queries1,'folder_data1')\n",
        "doc_vectors2,query_vectors2,vectorizer2 = vectorizerData(processed_docs2,processed_queries2,'folder_data2')\n",
        "\n"
      ],
      "metadata": {
        "id": "Qc-dXDLu9OT0"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# load tfdif from file and calculate cosine similarities\n",
        "def match_document_query(query_tfidf_vector,tfidf_matrix):\n",
        "        cosine_similarities = cosine_similarity(\n",
        "            query_tfidf_vector,\n",
        "            tfidf_matrix\n",
        "        ).flatten()\n",
        "        doc_indices_sorted = np.argsort(cosine_similarities)[::-1]\n",
        "        doc_indices_sorted = doc_indices_sorted[cosine_similarities[doc_indices_sorted] > 0]\n",
        "        return doc_indices_sorted\n"
      ],
      "metadata": {
        "id": "GRLMS4foQMBU"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Match Rank Documents"
      ],
      "metadata": {
        "id": "xL6LJykFC5Dt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def compute_similarity(query_vectors,doc_vectors):\n",
        "        return cosine_similarity(query_vectors, doc_vectors)\n",
        "\n",
        "def rank_documents(similarity_scores,queries,documents):\n",
        "        query_results = {}\n",
        "        for qid, scores in zip(queries.keys(), similarity_scores):\n",
        "            sorted_docs = sorted(enumerate(scores), key=lambda x: x[1], reverse=True)\n",
        "            query_results[qid] = [documents[idx]['doc_id'] for idx, _ in sorted_docs]\n",
        "        return query_results"
      ],
      "metadata": {
        "id": "cDosKY6uACMz"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "vEaw3lwUDma4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def average_precision(retrieved_docs, relevant_docs):\n",
        "        relevant_set = set(relevant_docs)\n",
        "        hits = 0\n",
        "        sum_precisions = 0\n",
        "        for i, doc_id in enumerate(retrieved_docs):\n",
        "            if doc_id in relevant_set:\n",
        "                hits += 1\n",
        "                sum_precisions += hits / (i + 1)\n",
        "        return sum_precisions / len(relevant_docs) if relevant_docs else 0\n",
        "\n",
        "def reciprocal_rank(retrieved_docs, relevant_docs):\n",
        "        relevant_set = set(relevant_docs)\n",
        "        for i, doc_id in enumerate(retrieved_docs):\n",
        "            if doc_id in relevant_set:\n",
        "                return 1 / (i + 1)\n",
        "        return 0\n",
        "\n",
        "def precision_at_k(retrieved_docs, relevant_docs, k=10):\n",
        "        relevant_set = set(relevant_docs)\n",
        "        retrieved_set = set(retrieved_docs[:k])\n",
        "        true_positives = len(relevant_set & retrieved_set)\n",
        "        return true_positives / k\n",
        "\n",
        "def recall(retrieved_docs, relevant_docs):\n",
        "        relevant_set = set(relevant_docs)\n",
        "        retrieved_set = set(retrieved_docs)\n",
        "        true_positives = len(relevant_set & retrieved_set)\n",
        "        return true_positives / len(relevant_set) if relevant_set else 0\n",
        "\n",
        "\n",
        "\n",
        "def calculate_metrics(qrels,queries,documents,query_vectors,doc_vectors):\n",
        "        similarity_scores = compute_similarity(query_vectors,doc_vectors)\n",
        "        query_results = rank_documents(similarity_scores,queries,documents)\n",
        "\n",
        "        map_scores = []\n",
        "        mrr_scores = []\n",
        "        recall_scores = []\n",
        "        precision_at_10_scores = []\n",
        "\n",
        "        for qid, rel_docs in qrels.items():\n",
        "            relevant_docs = [doc_id for doc_id, score in rel_docs if score > 0]\n",
        "            retrieved_docs = query_results.get(qid, [])\n",
        "\n",
        "            ap = average_precision(retrieved_docs, relevant_docs)\n",
        "            rr = reciprocal_rank(retrieved_docs, relevant_docs)\n",
        "            rec = recall(retrieved_docs, relevant_docs)\n",
        "            prec_10 = precision_at_k(retrieved_docs, relevant_docs)\n",
        "\n",
        "            map_scores.append(ap)\n",
        "            mrr_scores.append(rr)\n",
        "            recall_scores.append(rec)\n",
        "            precision_at_10_scores.append(prec_10)\n",
        "\n",
        "        return {\n",
        "            'MAP': (sum(map_scores) / len(map_scores))*100  if map_scores else 0,\n",
        "            'MRR': (sum(mrr_scores) / len(mrr_scores))*100 if mrr_scores else 0,\n",
        "            'Average Recall': (sum(recall_scores) / len(recall_scores))*100 if recall_scores else 0,\n",
        "            'Precision@10': (sum(precision_at_10_scores) / len(precision_at_10_scores))*100 if precision_at_10_scores else 0,\n",
        "        }\n"
      ],
      "metadata": {
        "id": "-pmrMP4WD3fE"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_metrics(qrels1,queries1,documents1,query_vectors1,doc_vectors1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVze7MrYD7Tj",
        "outputId": "ee77c6f4-32fe-4f74-bef9-ba1e6d37597d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'MAP': 2.6760579671677447,\n",
              " 'MRR': 2.6760579671677447,\n",
              " 'Average Recall': 100.0,\n",
              " 'Precision@10': 0.6818181818181818}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uKF3cD3LUGqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_metrics(qrels2,queries2,documents2,query_vectors2,doc_vectors2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "CHawYuJrEFGA",
        "outputId": "7ce5edc5-5809-40f1-85d0-ae99b2e94460"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "sparse array length is ambiguous; use getnnz() or shape[0]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-47f8db7e3372>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcalculate_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqrels2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mqueries2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdocuments2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mquery_vectors2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdoc_vectors2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-1c9edfdef1ca>\u001b[0m in \u001b[0;36mcalculate_metrics\u001b[0;34m(qrels, queries, documents, query_vectors, doc_vectors)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0msimilarity_scores_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         similarity_scores = np.memmap(similarity_scores_file, dtype=np.float32, mode='w+',\n\u001b[0;32m---> 20\u001b[0;31m                                      shape=(len(query_vectors), len(doc_vectors)))\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0msimilarity_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_vectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/sparse/_base.py\u001b[0m in \u001b[0;36m__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0;31m# non-zeros is more important.  For now, raise an exception!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m         raise TypeError(\"sparse array length is ambiguous; use getnnz()\"\n\u001b[0m\u001b[1;32m    341\u001b[0m                         \" or shape[0]\")\n\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: sparse array length is ambiguous; use getnnz() or shape[0]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zf9yYVE0FTjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimizer"
      ],
      "metadata": {
        "id": "ac34PNLxdyZC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clustering"
      ],
      "metadata": {
        "id": "QvZTN0fKeJrk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_query(query, vectorizer):\n",
        "    processed_query = preprocess_text(query)\n",
        "    query_vector = vectorizer.transform([processed_query])\n",
        "    return processed_query,query_vector\n"
      ],
      "metadata": {
        "id": "paDOHmSApBxN"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_query,query_vector = process_query(\"hi man\",vectorizer1)\n"
      ],
      "metadata": {
        "id": "rP99RtzH43uQ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9OOZTTt__32H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "\n",
        "def perform_clustering(doc_vectors, n_clusters, folder_name):\n",
        "    # Define file paths\n",
        "    kmeans_file = os.path.join(folder_name, 'kmeans_model.pkl')\n",
        "\n",
        "    # Check if the model already exists\n",
        "    if os.path.exists(kmeans_file):\n",
        "        # Load existing model\n",
        "        with open(kmeans_file, 'rb') as f:\n",
        "            kmeans = pickle.load(f)\n",
        "    else:\n",
        "        # Perform clustering\n",
        "        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(doc_vectors)\n",
        "        # Save the model\n",
        "        with open(kmeans_file, 'wb') as f:\n",
        "            pickle.dump(kmeans, f)\n",
        "\n",
        "    return kmeans\n",
        "\n",
        "# Specify the number of clusters\n",
        "n_clusters = 2\n",
        "kmeans1 = perform_clustering(doc_vectors1, n_clusters, 'folder_data1')\n",
        "kmeans2 = perform_clustering(doc_vectors2, n_clusters, 'folder_data2')\n"
      ],
      "metadata": {
        "id": "Q_teGniBCf7H"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        " # load tfdif from file and clustering file and calculate cosine similarities\n",
        "def match_document_query_with_clustering(doc_vectors1temp,query_tfidf_vector,kmeans):\n",
        "        tfidf_matrix = doc_vectors1temp\n",
        "        label = kmeans.predict(query_tfidf_vector)[0]\n",
        "        cluster_indices = [i for i, l in enumerate(kmeans.labels_) if l == label]\n",
        "        similarity_scores = cosine_similarity(query_tfidf_vector, tfidf_matrix[cluster_indices]).flatten()\n",
        "        doc_indices_sorted = np.argsort(similarity_scores)[::-1]\n",
        "        doc_indices_sorted = doc_indices_sorted[similarity_scores[doc_indices_sorted] > 0]\n",
        "        return doc_indices_sorted\n"
      ],
      "metadata": {
        "id": "YJIaBZboDEU0"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_results = match_document_query_with_clustering(doc_vectors1,query_vector, kmeans1)\n"
      ],
      "metadata": {
        "id": "3Wz6rb4LRi94"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRI17Q2SThqT",
        "outputId": "da066a2e-07b8-45f0-a50e-6f1b6f9a3305"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 27188, 180284, 268909, ...,  46780, 130171, 232023])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_metrics_with_clustering(qrels, queries, documents, query_vectors, doc_vectors, kmeans):\n",
        "    similarity_scores = []  # This will hold similarity scores for each query\n",
        "    query_results = {}  # This will hold the final ranked document IDs for each query\n",
        "\n",
        "    for qid, query_vector in zip(queries.keys(), query_vectors):\n",
        "        # Find cluster indices for the current query vector\n",
        "        doc_indices_sorted = match_document_query_with_clustering(doc_vectors, query_vector, kmeans)\n",
        "\n",
        "        # Extract the document IDs based on sorted indices\n",
        "        ranked_docs = [documents[idx]['doc_id'] for idx in doc_indices_sorted]\n",
        "\n",
        "        query_results[qid] = ranked_docs\n",
        "        # We store similarity scores if needed for further processing (not used in this example)\n",
        "        # similarity_scores.append(cosine_similarity(query_vector, doc_vectors[doc_indices_sorted]).flatten())\n",
        "\n",
        "    # Now calculate the evaluation metrics\n",
        "    map_scores = []\n",
        "    mrr_scores = []\n",
        "    recall_scores = []\n",
        "    precision_at_10_scores = []\n",
        "\n",
        "    for qid, rel_docs in qrels.items():\n",
        "        relevant_docs = [doc_id for doc_id, score in rel_docs if score > 0]\n",
        "        retrieved_docs = query_results.get(qid, [])\n",
        "\n",
        "        ap = average_precision(retrieved_docs, relevant_docs)\n",
        "        rr = reciprocal_rank(retrieved_docs, relevant_docs)\n",
        "        rec = recall(retrieved_docs, relevant_docs)\n",
        "        prec_10 = precision_at_k(retrieved_docs, relevant_docs)\n",
        "\n",
        "        map_scores.append(ap)\n",
        "        mrr_scores.append(rr)\n",
        "        recall_scores.append(rec)\n",
        "        precision_at_10_scores.append(prec_10)\n",
        "\n",
        "    return {\n",
        "        'MAP': (sum(map_scores) / len(map_scores)) * 100 if map_scores else 0,\n",
        "        'MRR': (sum(mrr_scores) / len(mrr_scores)) * 100 if mrr_scores else 0,\n",
        "        'Average Recall': (sum(recall_scores) / len(recall_scores)) * 100 if recall_scores else 0,\n",
        "        'Precision@10': (sum(precision_at_10_scores) / len(precision_at_10_scores)) * 100 if precision_at_10_scores else 0,\n",
        "    }\n"
      ],
      "metadata": {
        "id": "YQ4vI5lYU_3M"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *kmeans* *5*"
      ],
      "metadata": {
        "id": "5jAdQpNmX07Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_metrics_with_clustering(qrels1, queries1, documents1, query_vectors1, doc_vectors1, kmeans1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bBW8cmxXARA",
        "outputId": "16e6d7b7-4610-45f9-a7bd-b42be7f60126"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'MAP': 0.0002995300616742081,\n",
              " 'MRR': 0.0002995300616742081,\n",
              " 'Average Recall': 2.272727272727273,\n",
              " 'Precision@10': 0.0}"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *kmeans* *3*"
      ],
      "metadata": {
        "id": "J46RNMB1X4bM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_metrics_with_clustering(qrels1, queries1, documents1, query_vectors1, doc_vectors1, kmeans1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecPc9oD-X4yd",
        "outputId": "98efc11d-8393-4910-d0ec-18f47cdce4d2"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'MAP': 0.001150058140634537,\n",
              " 'MRR': 0.001150058140634537,\n",
              " 'Average Recall': 3.977272727272727,\n",
              " 'Precision@10': 0.0}"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *kmeans* *2*"
      ],
      "metadata": {
        "id": "lE8q90vwY4_C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_metrics_with_clustering(qrels1, queries1, documents1, query_vectors1, doc_vectors1, kmeans1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKli-CE7XbDz",
        "outputId": "215f85fe-3bc5-4ea6-df01-adf90b9639e9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'MAP': 0.000884231204417897,\n",
              " 'MRR': 0.000884231204417897,\n",
              " 'Average Recall': 4.545454545454546,\n",
              " 'Precision@10': 0.0}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# vector Store"
      ],
      "metadata": {
        "id": "1EZAs1HWabTM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install faiss-cpu  # For CPU\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FpNhO5lad2Z",
        "outputId": "ddb3c90a-a8b1-4c95-8baf-f802c3c9a618"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (1.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.25.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "def reduce_dimensions(doc_vectors, n_components=100):\n",
        "    svd = TruncatedSVD(n_components=n_components)\n",
        "    reduced_vectors = svd.fit_transform(doc_vectors)\n",
        "    return reduced_vectors.astype(np.float32)\n"
      ],
      "metadata": {
        "id": "__i7X7N9exmB"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "\n",
        "def build_faiss_index(reduced_vectors, dimension, nlist=100):\n",
        "    quantizer = faiss.IndexFlatL2(dimension)\n",
        "    index = faiss.IndexIVFFlat(quantizer, dimension, nlist, faiss.METRIC_L2)\n",
        "    index.train(reduced_vectors)\n",
        "    index.add(reduced_vectors)\n",
        "    return index\n"
      ],
      "metadata": {
        "id": "U-dAsq5ie-4j"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# مثال على تحميل بيانات\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "# تحويل مصفوفة المستندات إلى CSR وتقليل الأبعاد\n",
        "reduced_vectors = reduce_dimensions(doc_vectors1)\n",
        "\n",
        "# بناء المؤشر\n",
        "dimension = 100  # الأبعاد بعد التقليل\n",
        "faiss_index = build_faiss_index(reduced_vectors, dimension)"
      ],
      "metadata": {
        "id": "cf6E1PoXfRsI"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def search_with_faiss(query_vector, index, k=10):\n",
        "    # Assure query vector is in the correct shape and dtype\n",
        "    query_vector = query_vector.reshape(1, -1).astype(np.float32)\n",
        "    distances, indices = index.search(query_vector, k)\n",
        "    return indices\n"
      ],
      "metadata": {
        "id": "XAL2Q9REfZFS"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3bk-zJNJlU4n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# استخدام الاستعلام للبحث في المؤشر\n",
        "query_vector = reduced_vectors[0]  # مثال على استخدام أول متجه كاستعلام\n",
        "matched_indices = search_with_faiss(query_vector, faiss_index).flatten()\n",
        "\n",
        "print(\"Indices of matched documents:\", matched_indices)\n",
        "matched_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xv0-BvSAdCDj",
        "outputId": "6671351d-d710-437c-b2a4-dc0401472f38"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Indices of matched documents: [     0 286643 196005   1468 130607 381796 130609 130614 281751 375478]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([     0, 286643, 196005,   1468, 130607, 381796, 130609, 130614,\n",
              "       281751, 375478])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def search_with_faiss(query_vectors, index, k=10):\n",
        "    # Assumes query_vectors is a scipy sparse matrix or numpy array\n",
        "    distances, indices = index.search(query_vectors, k)\n",
        "    return indices\n"
      ],
      "metadata": {
        "id": "5f_LPgz4in8o"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_metrics_with_faiss(qrels, queries, index, query_vectors,documents):\n",
        "    map_scores = []\n",
        "    mrr_scores = []\n",
        "    recall_scores = []\n",
        "    precision_at_10_scores = []\n",
        "\n",
        "    # Assume query_vectors is already a matrix where each row is a vectorized query\n",
        "    # تحويل مصفوفة المستندات إلى CSR وتقليل الأبعاد\n",
        "    query_vectors = reduce_dimensions(query_vectors)\n",
        "\n",
        "    for qid, query_vector in zip(queries.keys(), query_vectors):\n",
        "        # Search with FAISS - adjust k as necessary\n",
        "\n",
        "        retrieved_indices = search_with_faiss(query_vector.reshape(1, -1), index, k=100)  # Make sure k is sufficient\n",
        "        retrieved_docs = [documents[idx]['doc_id'] for idx in retrieved_indices.flatten()]  # documents should be a list where index corresponds to doc IDs\n",
        "\n",
        "        # Extract relevant documents from qrels\n",
        "        relevant_docs = [doc_id for doc_id, rel in qrels[qid] if rel > 0]\n",
        "\n",
        "        # Calculate metrics for this query\n",
        "        ap = average_precision(retrieved_docs, relevant_docs)\n",
        "        rr = reciprocal_rank(retrieved_docs, relevant_docs)\n",
        "        rec = recall(retrieved_docs, relevant_docs)\n",
        "        prec_10 = precision_at_k(retrieved_docs, relevant_docs)\n",
        "\n",
        "        map_scores.append(ap)\n",
        "        mrr_scores.append(rr)\n",
        "        recall_scores.append(rec)\n",
        "        precision_at_10_scores.append(prec_10)\n",
        "\n",
        "    # Compute final scores\n",
        "    return {\n",
        "        'MAP': sum(map_scores) / len(map_scores) * 100 if map_scores else 0,\n",
        "        'MRR': sum(mrr_scores) / len(mrr_scores) * 100 if mrr_scores else 0,\n",
        "        'Average Recall': sum(recall_scores) / len(recall_scores) * 100 if recall_scores else 0,\n",
        "        'Precision@10': sum(precision_at_10_scores) / len(precision_at_10_scores) * 100 if precision_at_10_scores else 0,\n",
        "    }\n"
      ],
      "metadata": {
        "id": "npq9Ag2oa2ug"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_metrics_with_faiss(qrels1, queries1, faiss_index, query_vectors1,documents1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uRhWPgcgVzR",
        "outputId": "21ae9c0f-a506-43e7-ed27-95943bab27e6"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'MAP': 0.0, 'MRR': 0.0, 'Average Recall': 0.0, 'Precision@10': 0.0}"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    }
  ]
}